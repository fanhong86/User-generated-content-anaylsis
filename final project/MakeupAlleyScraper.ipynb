{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jtplot module in notebook\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# choose which theme to inherit plotting style from\n",
    "# onedork | grade3 | oceans16 | chesterish | monokai | solarizedl | solarizedd\n",
    "jtplot.style(theme='onedork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from robobrowser import RoboBrowser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Structure</h2>\n",
    "<ul>\n",
    "    <li>We can't access product reviews unless we're logged in as a registered user. So we have to handle login.</li>\n",
    "    <li>We will be using the most reviewed products page</li>\n",
    "    <li>We will focus on \"Foundation\" products</li>\n",
    "    <li>There are 7 different \"Foundation\" subcategories with its own unique \"CategoryID\" in its url\n",
    "        <ol>\n",
    "            <li><strong>Powder</strong> - CategoryID: 503</li>\n",
    "            <li><strong>Primer/Corrector</strong> - CategoryID: 504</li>\n",
    "            <li><strong>Stick</strong> - CategoryID: 506</li>\n",
    "            <li><strong>Tinted Moisturizer</strong> - CategoryID: 505</li>\n",
    "            <li><strong>Liquid</strong> - CategoryID: 502</li>\n",
    "            <li><strong>Crème</strong> - CategoryID: 501</li>\n",
    "            <li><strong>BB Cream</strong> - CategoryID: 507</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>For each subcategory there are products that each have\n",
    "        <ul>\n",
    "            <li><strong>Brand Name</strong> </li>\n",
    "            <li><strong>Product Name</strong> </li>\n",
    "            <li><strong>Category</strong> </li>\n",
    "            <li><strong>Average Rating</strong> </li>\n",
    "            <li><strong>Total Number of Reviews</strong> </li>\n",
    "            <li><strong>% That Would Buy Again</strong></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We will be scraping the first 5 pages of products for each subcategory, with the exception of \"Stick\" as \"Stick\" only has 2 pages of products, and so we will only scrape two pages of products for \"Stick\"</li>\n",
    "    <li>When we click on a product page there are reviews on the bottom. For each review we will scrape\n",
    "        <ul>\n",
    "            <li><strong>Rating</strong> - 1 to 5 lipsticks (aka stars)</li>\n",
    "            <li><strong>username</strong> </li>\n",
    "            <li><strong>date</strong> - date that the review was posted</li>\n",
    "            <li><strong>age</strong> - age range of the reviewer</li>\n",
    "            <li><strong>skin</strong> - skin information of the reviewer</li>\n",
    "            <li><strong>hair</strong> - hair information of the reviewer</li>\n",
    "            <li><strong>eyes</strong> - eye color of the reviewer</li>\n",
    "            <li><strong>review</strong> - the review itself</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login_url\n",
    "login_url = \"https://www.makeupalley.com/account/login.asp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python37\\lib\\site-packages\\robobrowser\\browser.py:40: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 40 of the file c:\\python\\python37\\lib\\site-packages\\robobrowser\\browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  features=self.browser.parser,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Username: ugca\n",
      "Enter Password: barua123\n",
      "Login Successful!\n"
     ]
    }
   ],
   "source": [
    "# let's login\n",
    "browser = RoboBrowser(history=True)\n",
    "browser.open(login_url)\n",
    "form = browser.get_form(action='/account/login.asp')\n",
    "\n",
    "form[\"UserName\"] = input(\"Enter Username: \")\n",
    "form[\"Password\"] = input(\"Enter Password: \")\n",
    "browser.session.headers['Referer'] = login_url\n",
    "\n",
    "browser.submit_form(form)\n",
    "# print(str(browser.select))\n",
    "\n",
    "print(\"Login Successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the different categories in a list\n",
    "categories = [\n",
    "    \"Powder\",\n",
    "    \"Primer/Corrector\",\n",
    "    \"Stick\",\n",
    "    \"Tinted Moisturizer\",\n",
    "    \"Liquid\",\n",
    "    \"Crème\",\n",
    "    \"BB Cream\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to to match each Subcategory with its CategoryID\n",
    "cat_id = dict()\n",
    "cat_id[\"Powder\"] = 503\n",
    "cat_id[\"Primer/Corrector\"] = 504\n",
    "cat_id[\"Stick\"] = 506\n",
    "cat_id[\"Tinted Moisturizer\"] = 505\n",
    "cat_id[\"Liquid\"] = 502\n",
    "cat_id[\"Crème\"] = 501\n",
    "cat_id[\"BB Cream\"] = 507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store product info: brand_name, product_name, category, average_rating, total_reviews, buy_again_percentage%\n",
    "product_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store output for each review: product_name, rating, username, date, age, skin, hair, eyes, review\n",
    "reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.makeupalley.com/product/browse.asp/page=1/pagesize=15/CategoryId=503/topten=reviewed/AgeRange=0/\n",
      "product_id: 9246 Scraping\n",
      "product_id: 9246 Complete\n",
      "product_id: 25754 Scraping\n",
      "product_id: 25754 Complete\n",
      "product_id: 15111 Scraping\n",
      "product_id: 15111 Complete\n",
      "product_id: 78607 Scraping\n",
      "product_id: 78607 Complete\n",
      "product_id: 74290 Scraping\n",
      "product_id: 74290 Complete\n",
      "product_id: 120907 Scraping\n",
      "product_id: 120907 Complete\n",
      "product_id: 13145 Scraping\n",
      "product_id: 13145 Complete\n",
      "product_id: 100359 Scraping\n",
      "product_id: 100359 Complete\n",
      "product_id: 89705 Scraping\n",
      "product_id: 89705 Complete\n",
      "product_id: 67857 Scraping\n",
      "product_id: 67857 Complete\n",
      "product_id: 102364 Scraping\n",
      "product_id: 102364 Complete\n",
      "product_id: 70540 Scraping\n",
      "product_id: 70540 Complete\n",
      "product_id: 11317 Scraping\n",
      "product_id: 11317 Complete\n",
      "product_id: 116379 Scraping\n",
      "product_id: 116379 Complete\n",
      "product_id: 921 Scraping\n",
      "product_id: 921 Complete\n",
      "https://www.makeupalley.com/product/browse.asp/page=2/pagesize=15/CategoryId=503/topten=reviewed/AgeRange=0/\n",
      "product_id: 79641 Scraping\n",
      "product_id: 79641 Complete\n",
      "product_id: 2970 Scraping\n",
      "product_id: 2970 Complete\n",
      "product_id: 512 Scraping\n",
      "product_id: 512 Complete\n",
      "product_id: 7276 Scraping\n",
      "product_id: 7276 Complete\n",
      "product_id: 68241 Scraping\n",
      "product_id: 68241 Complete\n",
      "product_id: 100905 Scraping\n",
      "product_id: 100905 Complete\n",
      "product_id: 88833 Scraping\n",
      "product_id: 88833 Complete\n",
      "product_id: 73012 Scraping\n",
      "product_id: 73012 Complete\n",
      "product_id: 14628 Scraping\n",
      "product_id: 14628 Complete\n",
      "product_id: 53022 Scraping\n",
      "product_id: 53022 Complete\n",
      "product_id: 6967 Scraping\n",
      "product_id: 6967 Complete\n",
      "product_id: 100494 Scraping\n",
      "product_id: 100494 Complete\n",
      "product_id: 1193 Scraping\n",
      "product_id: 1193 Complete\n",
      "product_id: 83371 Scraping\n",
      "product_id: 83371 Complete\n",
      "product_id: 26048 Scraping\n",
      "product_id: 26048 Complete\n",
      "https://www.makeupalley.com/product/browse.asp/page=3/pagesize=15/CategoryId=503/topten=reviewed/AgeRange=0/\n",
      "product_id: 17368 Scraping\n",
      "product_id: 17368 Complete\n",
      "product_id: 6666 Scraping\n",
      "product_id: 6666 Complete\n",
      "product_id: 2083 Scraping\n",
      "product_id: 2083 Complete\n",
      "product_id: 6911 Scraping\n",
      "product_id: 6911 Complete\n",
      "product_id: 90835 Scraping\n",
      "product_id: 90835 Complete\n",
      "product_id: 138487 Scraping\n",
      "product_id: 138487 Complete\n",
      "product_id: 21593 Scraping\n",
      "product_id: 21593 Complete\n",
      "product_id: 100192 Scraping\n",
      "product_id: 100192 Complete\n",
      "product_id: 88122 Scraping\n",
      "product_id: 88122 Complete\n",
      "product_id: 150418 Scraping\n",
      "product_id: 150418 Complete\n",
      "product_id: 103353 Scraping\n",
      "product_id: 103353 Complete\n",
      "product_id: 69561 Scraping\n",
      "product_id: 69561 Complete\n",
      "product_id: 1357 Scraping\n",
      "product_id: 1357 Complete\n",
      "product_id: 69679 Scraping\n",
      "product_id: 69679 Complete\n",
      "product_id: 82658 Scraping\n",
      "product_id: 82658 Complete\n",
      "https://www.makeupalley.com/product/browse.asp/page=4/pagesize=15/CategoryId=503/topten=reviewed/AgeRange=0/\n",
      "product_id: 1236 Scraping\n",
      "product_id: 1236 Complete\n",
      "product_id: 150181 Scraping\n",
      "product_id: 150181 Complete\n",
      "product_id: 140723 Scraping\n",
      "product_id: 140723 Complete\n",
      "product_id: 8464 Scraping\n",
      "product_id: 8464 Complete\n",
      "product_id: 83952 Scraping\n",
      "product_id: 83952 Complete\n",
      "product_id: 126443 Scraping\n",
      "product_id: 126443 Complete\n",
      "product_id: 87481 Scraping\n",
      "product_id: 87481 Complete\n",
      "product_id: 54255 Scraping\n",
      "product_id: 54255 Complete\n",
      "product_id: 12102 Scraping\n",
      "product_id: 12102 Complete\n",
      "product_id: 164197 Scraping\n",
      "product_id: 164197 Complete\n",
      "product_id: 155104 Scraping\n",
      "product_id: 155104 Complete\n",
      "product_id: 158862 Scraping\n",
      "product_id: 158862 Complete\n",
      "product_id: 152994 Scraping\n",
      "product_id: 152994 Complete\n",
      "product_id: 6344 Scraping\n",
      "product_id: 6344 Complete\n",
      "product_id: 83471 Scraping\n",
      "product_id: 83471 Complete\n",
      "https://www.makeupalley.com/product/browse.asp/page=5/pagesize=15/CategoryId=503/topten=reviewed/AgeRange=0/\n",
      "product_id: 105178 Scraping\n",
      "product_id: 105178 Complete\n",
      "product_id: 61941 Scraping\n",
      "product_id: 61941 Complete\n",
      "product_id: 160635 Scraping\n",
      "product_id: 160635 Complete\n",
      "product_id: 103298 Scraping\n",
      "product_id: 103298 Complete\n",
      "product_id: 109479 Scraping\n",
      "product_id: 109479 Complete\n",
      "product_id: 9405 Scraping\n",
      "product_id: 9405 Complete\n",
      "product_id: 10892 Scraping\n",
      "product_id: 10892 Complete\n",
      "product_id: 96670 Scraping\n",
      "product_id: 96670 Complete\n",
      "product_id: 156790 Scraping\n",
      "product_id: 156790 Complete\n",
      "product_id: 35472 Scraping\n",
      "product_id: 35472 Complete\n",
      "product_id: 87755 Scraping\n",
      "product_id: 87755 Complete\n",
      "product_id: 101784 Scraping\n",
      "product_id: 101784 Complete\n",
      "product_id: 107447 Scraping\n",
      "product_id: 107447 Complete\n",
      "product_id: 2078 Scraping\n",
      "product_id: 2078 Complete\n",
      "product_id: 66511 Scraping\n",
      "product_id: 66511 Complete\n",
      "https://www.makeupalley.com/product/browse.asp/page=1/pagesize=15/CategoryId=504/topten=reviewed/AgeRange=0/\n",
      "product_id: 6572 Scraping\n",
      "product_id: 6572 Complete\n",
      "product_id: 133822 Scraping\n",
      "product_id: 133822 Complete\n",
      "product_id: 800 Scraping\n",
      "product_id: 800 Complete\n",
      "product_id: 128511 Scraping\n",
      "product_id: 128511 Complete\n",
      "product_id: 98437 Scraping\n",
      "product_id: 98437 Complete\n",
      "product_id: 663 Scraping\n",
      "product_id: 663 Complete\n",
      "product_id: 61131 Scraping\n",
      "product_id: 61131 Complete\n",
      "product_id: 132200 Scraping\n"
     ]
    }
   ],
   "source": [
    "# skeleton url\n",
    "base_url = \"https://www.makeupalley.com/product/browse.asp/page=/pagesize=15/CategoryId=/topten=reviewed/AgeRange=0/\"\n",
    "base = \"https://www.makeupalley.com\"\n",
    "\n",
    "# iterate through each category of foundation\n",
    "for cat in categories:\n",
    "    # 2 pages of products for stick\n",
    "    if(cat == \"Stick\"):\n",
    "        for i in range(1,3):\n",
    "            # adjust the urls\n",
    "            product_url = base_url.replace(\"page=\", \"page=\" + str(i))\n",
    "            product_url = product_url.replace(\"CategoryId=\", \"CategoryId=\" + str(cat_id[cat]))\n",
    "            \n",
    "            # collect the url with the requests library\n",
    "            page = requests.get(product_url)\n",
    "            print(product_url)\n",
    "            \n",
    "            # get the html of the page in string form\n",
    "            page_html = page.text\n",
    "\n",
    "            # create the BeautifulSoup object that takes in the html in str form and a html/xml parser of choice either html.parser or lxml\n",
    "            soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "            # Pull all text from the div class : search-results\n",
    "            product_search_results = soup.find(class_ = \"search-results\")\n",
    "            \n",
    "            # Grab all the rows of products\n",
    "            product_list = product_search_results.find_all(\"tr\")\n",
    "            \n",
    "            # get the attributes\n",
    "            for product in product_list:\n",
    "                # store product data\n",
    "                row_product_data = []\n",
    "                \n",
    "                # grab all column information\n",
    "                columns = product.find_all(\"td\")\n",
    "                \n",
    "                # store variable for the product link\n",
    "                product_link = \"\"\n",
    "                for col in range(len(columns)):\n",
    "                    # first column is brand\n",
    "                    if(col == 0):\n",
    "                        row_product_data.append(columns[col].text)\n",
    "                        #print(columns[col].text)\n",
    "                    \n",
    "                    # second column is the product\n",
    "                    elif(col == 1):\n",
    "                        product_name = columns[col].find_all(\"a\", href = True)[1]\n",
    "                        row_product_data.append(product_name.text)\n",
    "                        product_link = base + product_name[\"href\"]\n",
    "                        #print(product_name.text)\n",
    "                       # print(product_link)\n",
    "                    \n",
    "                    # third column is the category name\n",
    "                    elif(col == 2):\n",
    "                        the_cat = columns[col].text \n",
    "                        row_product_data.append(the_cat)\n",
    "                       # print(the_cat)\n",
    "                        \n",
    "                    # fourth column is avg rating\n",
    "                    elif(col == 3):\n",
    "                        avg_rating = float(columns[col].text)\n",
    "                        row_product_data.append(avg_rating)\n",
    "                        #print(avg_rating)\n",
    "                    \n",
    "                    # fifth columns is number of reviews\n",
    "                    elif(col == 4):\n",
    "                        num_reviews = int(columns[col].text.replace(\",\", \"\"))\n",
    "                        row_product_data.append(num_reviews)\n",
    "                        #print(num_reviews)\n",
    "                        \n",
    "                    # sixth column is buy again percentage\n",
    "                    elif(col == 5):\n",
    "                        buy_again = float(columns[col].text.replace(\"%\", \"\")) / 100.0\n",
    "                        row_product_data.append(buy_again)\n",
    "                        #print(buy_again)\n",
    "                        \n",
    "                # throw this row data into the product_info list\n",
    "                if(len(row_product_data) != 0):\n",
    "                    product_info.append(row_product_data)\n",
    "                    \n",
    "                    # lets go to the product link\n",
    "                    #print(\"This the product link\")\n",
    "                    #print(product_link)\n",
    "                    product_page = requests.get(product_link)\n",
    "                    \n",
    "                    # get the html of the page in string form\n",
    "                    product_page_html = product_page.text\n",
    "                    \n",
    "                    # create the BeautifulSoup object that takes in the html in str form and a html/xml parser of choice either html.parser or lxml\n",
    "                    soup2 = BeautifulSoup(product_page_html, 'html.parser')\n",
    "                    \n",
    "                    # first find the product_id \n",
    "                    product_id_search = soup2.find(\"div\" , {\"id\":\"ItemId\"})\n",
    "                    try:\n",
    "                        product_id = product_id_search.text\n",
    "                        print(\"product_id:\", product_id, \"Scraping\")\n",
    "                        # grab the last page of reviews which is the href of the second to last div of class = track_paging_\n",
    "                        page_trackers = soup2.find_all(class_ = \"track_Paging_\", href = True)\n",
    "                        last_page = page_trackers[-2][\"href\"]\n",
    "                    except:\n",
    "                        print(\"this shit failed\")\n",
    "                        continue\n",
    "                         \n",
    "                    # do something hacky/ string manipulations to extract last page number\n",
    "                    last_page_number = last_page[:-1]\n",
    "                    start_index = last_page_number.find(\"page=\")\n",
    "                    last_page_number = int(last_page_number[start_index + 5:])\n",
    "                    \n",
    "                    #print(\"last_page:\", last_page)\n",
    "                    #print(\"last page number:\", last_page_number)\n",
    "                    \n",
    "                    # skeleton\n",
    "                    base_product_url = \"https://www.makeupalley.com/product/showreview.asp/ItemID=/page=/\"\n",
    "    \n",
    "                    # go through all the pages to scrape reviews!\n",
    "                    # last_page_number + 1\n",
    "                    for i in range(1, last_page_number + 1):\n",
    "                        # update the product url\n",
    "                        new_product_url = base_product_url.replace(\"ItemID=\",\"ItemID=\" + product_id)\n",
    "                        new_product_url = new_product_url.replace(\"page=\", \"page=\"+ str(i))\n",
    "                        #print(new_product_url)\n",
    "                        \n",
    "                        # get the html of the page in string form\n",
    "                        new_product_page = requests.get(new_product_url)\n",
    "                        new_product_page_html = new_product_page.text\n",
    "                        \n",
    "                        # create a beautiful soup object\n",
    "                        soup3 = BeautifulSoup(new_product_page_html, 'html.parser')\n",
    "                        \n",
    "                        comment_list = soup3.find(id = \"reviews-wrapper\")\n",
    "                        \n",
    "                        real_comment_list = comment_list.find_all(class_ = \"comments\")\n",
    "                        \n",
    "                        # iterate through each comment\n",
    "                        for comment in real_comment_list:\n",
    "                            # store row data\n",
    "                            row = []\n",
    "                            \n",
    "                            # get the productname\n",
    "                            row.append(product_name.text)\n",
    "                            \n",
    "                            # get the ratings\n",
    "                            rating = comment.find(class_ = \"lipies\")\n",
    "                            score = rating.find(\"span\")\n",
    "                            row.append(score[\"class\"][0][2])\n",
    "                            \n",
    "                            # get username\n",
    "                            username = comment.find(class_ = \"user-name\")\n",
    "                            row.append(username.text.replace(\"\\t\", \"\"))\n",
    "                            \n",
    "                            # get the date\n",
    "                            date = comment.find(class_ = \"date\")\n",
    "                            row.append(date.text)\n",
    "                            \n",
    "                            # get age, skin, hair, and eyes\n",
    "                            traits = comment.find(class_ = \"important\")\n",
    "                            clean_traits = traits.text.replace(\"Age:\", \"\")\n",
    "                            clean_traits = clean_traits.replace(\"Skin\", \"\")\n",
    "                            clean_traits = clean_traits.replace(\"Hair\", \"\")\n",
    "                            clean_traits = clean_traits.replace(\"Eyes\", \"\")\n",
    "                            clean_traits = clean_traits.split(\":\")\n",
    "                            for k in range(len(clean_traits)):\n",
    "                                row.append(clean_traits[k].strip())\n",
    "                            \n",
    "                            # get the review\n",
    "                            review = comment.find(class_ = \"break-word\")\n",
    "                            try:\n",
    "                                row.append(review.text.replace(\"\\t\",\"\"))\n",
    "                            except:\n",
    "                                try:\n",
    "                                    review = comment.find(class_ = \"1break-word\")\n",
    "                                    row.append(review.text.replace(\"\\t\", \"\"))\n",
    "                                except:\n",
    "                                    print(\"it didn't work\")\n",
    "                                    continue\n",
    "                            \n",
    "                            # throw the row of data into reviews\n",
    "                            reviews.append(row)\n",
    "                    print(\"product_id:\", product_id, \"Complete\")\n",
    "                    \n",
    "    # 5 pages of products for the rest\n",
    "    else:\n",
    "        for i in range(1,6):\n",
    "            # adjust the urls\n",
    "            product_url = base_url.replace(\"page=\", \"page=\" + str(i))\n",
    "            product_url = product_url.replace(\"CategoryId=\", \"CategoryId=\" + str(cat_id[cat]))\n",
    "            \n",
    "            # collect the url with the requests library\n",
    "            page = requests.get(product_url)\n",
    "            print(product_url)\n",
    "            \n",
    "            # get the html of the page in string form\n",
    "            page_html = page.text\n",
    "\n",
    "            # create the BeautifulSoup object that takes in the html in str form and a html/xml parser of choice either html.parser or lxml\n",
    "            soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "            # Pull all text from the div class : search-results\n",
    "            product_search_results = soup.find(class_ = \"search-results\")\n",
    "            \n",
    "            # Grab all the rows of products\n",
    "            product_list = product_search_results.find_all(\"tr\")\n",
    "            \n",
    "            # get the attributes\n",
    "            for product in product_list:\n",
    "                # store product data\n",
    "                row_product_data = []\n",
    "                \n",
    "                # grab all column information\n",
    "                columns = product.find_all(\"td\")\n",
    "                \n",
    "                # store variable for the product link\n",
    "                product_link = \"\"\n",
    "                for col in range(len(columns)):\n",
    "                    # first column is brand\n",
    "                    if(col == 0):\n",
    "                        row_product_data.append(columns[col].text)\n",
    "                        #print(columns[col].text)\n",
    "                    \n",
    "                    # second column is the product\n",
    "                    elif(col == 1):\n",
    "                        product_name = columns[col].find_all(\"a\", href = True)[1]\n",
    "                        row_product_data.append(product_name.text)\n",
    "                        product_link = base + product_name[\"href\"]\n",
    "                        #print(product_name.text)\n",
    "                       # print(product_link)\n",
    "                    \n",
    "                    # third column is the category name\n",
    "                    elif(col == 2):\n",
    "                        the_cat = columns[col].text \n",
    "                        row_product_data.append(the_cat)\n",
    "                       # print(the_cat)\n",
    "                        \n",
    "                    # fourth column is avg rating\n",
    "                    elif(col == 3):\n",
    "                        avg_rating = float(columns[col].text)\n",
    "                        row_product_data.append(avg_rating)\n",
    "                        #print(avg_rating)\n",
    "                    \n",
    "                    # fifth columns is number of reviews\n",
    "                    elif(col == 4):\n",
    "                        num_reviews = int(columns[col].text.replace(\",\", \"\"))\n",
    "                        row_product_data.append(num_reviews)\n",
    "                        #print(num_reviews)\n",
    "                        \n",
    "                    # sixth column is buy again percentage\n",
    "                    elif(col == 5):\n",
    "                        buy_again = float(columns[col].text.replace(\"%\", \"\")) / 100.0\n",
    "                        row_product_data.append(buy_again)\n",
    "                        #print(buy_again)\n",
    "                        \n",
    "                # throw this row data into the product_info list\n",
    "                if(len(row_product_data) != 0):\n",
    "                    product_info.append(row_product_data)\n",
    "                    \n",
    "                    # lets go to the product link\n",
    "                    #print(\"This the product link\")\n",
    "                    #print(product_link)\n",
    "                    product_page = requests.get(product_link)\n",
    "                    \n",
    "                    # get the html of the page in string form\n",
    "                    product_page_html = product_page.text\n",
    "                    \n",
    "                    # create the BeautifulSoup object that takes in the html in str form and a html/xml parser of choice either html.parser or lxml\n",
    "                    soup2 = BeautifulSoup(product_page_html, 'html.parser')\n",
    "                    \n",
    "                    # first find the product_id \n",
    "                    product_id_search = soup2.find(\"div\" , {\"id\":\"ItemId\"})\n",
    "                    try:\n",
    "                        product_id = product_id_search.text\n",
    "                        print(\"product_id:\", product_id, \"Scraping\")\n",
    "                        page_trackers = soup2.find_all(class_ = \"track_Paging_\", href = True)\n",
    "                        last_page = page_trackers[-2][\"href\"]\n",
    "                    except:\n",
    "                        print(\"this shit failed\")\n",
    "                        continue\n",
    "                    \n",
    "                    # do something hacky/ string manipulations to extract last page number\n",
    "                    last_page_number = last_page[:-1]\n",
    "                    start_index = last_page_number.find(\"page=\")\n",
    "                    last_page_number = int(last_page_number[start_index + 5:])\n",
    "                    \n",
    "                    #print(\"last_page:\", last_page)\n",
    "                    #print(\"last page number:\", last_page_number)\n",
    "                    \n",
    "                    # skeleton\n",
    "                    base_product_url = \"https://www.makeupalley.com/product/showreview.asp/ItemID=/page=/\"\n",
    "    \n",
    "                    # go through all the pages to scrape reviews!\n",
    "                    # last_page_number + 1\n",
    "                    for i in range(1, last_page_number + 1):\n",
    "                        # update the product url\n",
    "                        new_product_url = base_product_url.replace(\"ItemID=\",\"ItemID=\" + product_id)\n",
    "                        new_product_url = new_product_url.replace(\"page=\", \"page=\"+ str(i))\n",
    "                        #print(new_product_url)\n",
    "                        \n",
    "                        # get the html of the page in string form\n",
    "                        new_product_page = requests.get(new_product_url)\n",
    "                        new_product_page_html = new_product_page.text\n",
    "                        \n",
    "                        # create a beautiful soup object\n",
    "                        soup3 = BeautifulSoup(new_product_page_html, 'html.parser')\n",
    "                        \n",
    "                        comment_list = soup3.find(id = \"reviews-wrapper\")\n",
    "                        \n",
    "                        real_comment_list = comment_list.find_all(class_ = \"comments\")\n",
    "                        \n",
    "                        # iterate through each comment\n",
    "                        for comment in real_comment_list:\n",
    "                            # store row data\n",
    "                            row = []\n",
    "                            \n",
    "                            # get the productname\n",
    "                            row.append(product_name.text)\n",
    "                            \n",
    "                            # get the ratings\n",
    "                            rating = comment.find(class_ = \"lipies\")\n",
    "                            score = rating.find(\"span\")\n",
    "                            row.append(score[\"class\"][0][2])\n",
    "                            \n",
    "                            # get username\n",
    "                            username = comment.find(class_ = \"user-name\")\n",
    "                            row.append(username.text.replace(\"\\t\", \"\"))\n",
    "                            \n",
    "                            # get the date\n",
    "                            date = comment.find(class_ = \"date\")\n",
    "                            row.append(date.text)\n",
    "                            \n",
    "                            # get age, skin, hair, and eyes\n",
    "                            traits = comment.find(class_ = \"important\")\n",
    "                            clean_traits = traits.text.replace(\"Age:\", \"\")\n",
    "                            clean_traits = clean_traits.replace(\"Skin\", \"\")\n",
    "                            clean_traits = clean_traits.replace(\"Hair\", \"\")\n",
    "                            clean_traits = clean_traits.replace(\"Eyes\", \"\")\n",
    "                            clean_traits = clean_traits.split(\":\")\n",
    "                            for k in range(len(clean_traits)):\n",
    "                                row.append(clean_traits[k].strip())\n",
    "                            \n",
    "                            # get the review\n",
    "                            review = comment.find(class_ = \"break-word\")\n",
    "                            try:\n",
    "                                row.append(review.text.replace(\"\\t\",\"\"))\n",
    "                            except:\n",
    "                                try:\n",
    "                                    review = comment.find(class_ = \"1break-word\")\n",
    "                                    row.append(review.text.replace(\"\\t\", \"\"))\n",
    "                                except:\n",
    "                                    print(\"it didn't work\")\n",
    "                                    continue\n",
    "                            \n",
    "                            # throw the row of data into reviews\n",
    "                            reviews.append(row)\n",
    "                            \n",
    "                    print(\"product_id:\", product_id, \"Complete\")\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.DataFrame(product_info, columns = [\"Brand\", \"Product\", \"Type\", \"Avg Rating\", \"Number of Reviews\", \"Percentage Would Buy Again\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.DataFrame(reviews, columns = [\"Product\", \"Rating\", \"Username\", \"Date\", \"Age\", \"Skin\", \"Hair\", \"Eyes\", \"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.to_csv(\"products.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
