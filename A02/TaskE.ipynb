{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task E\n",
    "_Use the location data collected in step A to find out lifts and sentiments regarding the candidates in large versus small cities/towns in Texas._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all tweets into dataframs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tot_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5741, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tennessee, USA</td>\n",
       "      <td>b\"RT @AliAdair22: \\xf0\\x9f\\x90\\xa6Next, Beto O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b\"RT @AliAdair22: \\xf0\\x9f\\x90\\xa6Next, Beto O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b\"Ted Cruz, Beto O'Rourke try to rally Latino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>America</td>\n",
       "      <td>b'RT @RonNehring: Third poll now showing Cruz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West Texas</td>\n",
       "      <td>b'Beto O\\xe2\\x80\\x99Rourke, the Democratic con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         location                                               text\n",
       "0  Tennessee, USA  b\"RT @AliAdair22: \\xf0\\x9f\\x90\\xa6Next, Beto O...\n",
       "1             NaN  b\"RT @AliAdair22: \\xf0\\x9f\\x90\\xa6Next, Beto O...\n",
       "2             NaN  b\"Ted Cruz, Beto O'Rourke try to rally Latino ...\n",
       "3         America  b'RT @RonNehring: Third poll now showing Cruz ...\n",
       "4      West Texas  b'Beto O\\xe2\\x80\\x99Rourke, the Democratic con..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a function to take care of the names\n",
    "def replace_names(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    beto_words = ['@betoorourke' , '#betoorourke', '#betonbeto', '#betoforsenate', \"beto o'rourke\", \"o'rourke\", 'rourke', '#vetobeto', '#vetobetofortexas']\n",
    "    cruz_words = ['@tedcruz', '#tedcruz', '#cruzcrew', '#choosecruz' 'ted cruz', 'ted']\n",
    "    \n",
    "    for w in beto_words:\n",
    "        try:\n",
    "            text = text.replace(w, 'beto')\n",
    "        except:\n",
    "            pass\n",
    "    for w in cruz_words:\n",
    "        try:\n",
    "            text = text.replace(w, 'cruz')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply replace_names() on each tweet\n",
    "text_column = []\n",
    "for t in tweets.itertuples():\n",
    "    text = t.text\n",
    "    new_text = replace_names(text)\n",
    "    text_column.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.text = text_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5741, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Houston', 'San Antonio', 'Dallas', 'Austin', 'Fort Worth', 'El Paso', 'Arlington', 'Corpus Christi', 'Plano', 'Laredo', 'Lubbock']\n"
     ]
    }
   ],
   "source": [
    "# Let's get a list of what we'll consider big cities/towns in Texas.\n",
    "large_cities = open('large_cities.txt', 'r')\n",
    "cities = []\n",
    "for line in large_cities:\n",
    "    l = line.strip()\n",
    "    l_list = l.split()\n",
    "    if l_list[2].isalpha():\n",
    "        city = l_list[1] + ' ' + l_list[2]\n",
    "    else:\n",
    "        city = l_list[1]\n",
    "    cities.append(city)\n",
    "cities = cities[0:11]\n",
    "print (cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column for location that is either Big, Small, or none\n",
    "location_column = []\n",
    "for t in tweets.itertuples():\n",
    "    if type(t.location) == str:\n",
    "        for c in cities:\n",
    "            if c in t.location:\n",
    "                location_column.append('Big')\n",
    "                break\n",
    "            elif c == cities[-1] and (', TX' in t.location or ', Texas' in t.location):\n",
    "                location_column.append('Small')\n",
    "                break\n",
    "            elif c == cities[-1]:\n",
    "                location_column.append('none')\n",
    "                break\n",
    "    else:\n",
    "        location_column.append('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace old location column with new\n",
    "tweets.location = location_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5741, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>b\"rt @aliadair22: \\xf0\\x9f\\x90\\xa6next, beto b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>b\"rt @aliadair22: \\xf0\\x9f\\x90\\xa6next, beto b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>b\"cruz cruz, beto try to rally latino voters i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>b'rt @ronnehring: third poll now showing cruz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>b'beto o\\xe2\\x80\\x99beto, the democratic congr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big</td>\n",
       "      <td>b'rt @wfaa: does texas\\xe2\\x80\\x99 senate race...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location                                               text\n",
       "0     none  b\"rt @aliadair22: \\xf0\\x9f\\x90\\xa6next, beto b...\n",
       "1     none  b\"rt @aliadair22: \\xf0\\x9f\\x90\\xa6next, beto b...\n",
       "2     none  b\"cruz cruz, beto try to rally latino voters i...\n",
       "3     none  b'rt @ronnehring: third poll now showing cruz ...\n",
       "4     none  b'beto o\\xe2\\x80\\x99beto, the democratic congr...\n",
       "5      Big  b'rt @wfaa: does texas\\xe2\\x80\\x99 senate race..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Lift for Candidate / City size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get count of tweets mentioning Beto / Cruz, and count of all tweets with Beto and/or Cruz in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "beto_count = 0\n",
    "cruz_count = 0\n",
    "n_tweets = 0\n",
    "for t in tweets.itertuples():\n",
    "    if t.location != 'none':\n",
    "        if 'beto' in t.text and 'cruz' in t.text:\n",
    "            beto_count += 1\n",
    "            cruz_count += 1\n",
    "            n_tweets += 1\n",
    "        elif 'beto' in t.text:\n",
    "            beto_count += 1\n",
    "            n_tweets += 1\n",
    "        elif 'cruz' in t.text:\n",
    "            cruz_count += 1        \n",
    "            n_tweets += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get count of tweets from large / small cities in Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_city_count = 0\n",
    "small_city_count = 0\n",
    "for t in tweets.itertuples():\n",
    "    if t.location == 'Big':\n",
    "        big_city_count += 1\n",
    "    elif t.location == 'Small':\n",
    "        small_city_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get count of tweets with Beto/Big, Beto/Small, Cruz/Big, Cruz/Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_count = 0\n",
    "bs_count = 0\n",
    "cb_count = 0\n",
    "cs_count = 0\n",
    "for t in tweets.itertuples():\n",
    "    if 'beto' in t.text and t.location == 'Big':\n",
    "        bb_count += 1\n",
    "    if 'beto' in t.text and t.location == 'Small':\n",
    "        bs_count += 1\n",
    "    if 'cruz' in t.text and t.location == 'Big':\n",
    "        cb_count += 1\n",
    "    if 'cruz' in t.text and t.location == 'Small':\n",
    "        cs_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate lift Beto/Big, Beto/Small, Cruz/Big, Cruz/Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_counts = [beto_count, cruz_count]\n",
    "city_counts = [big_city_count, small_city_count]\n",
    "combo_counts = [bb_count, bs_count, cb_count, cs_count]\n",
    "lifts = [] # order: [0] beto vs big, [1] beto vs small, [2] cruz vs big, [3] cruz vs small\n",
    "i = 0\n",
    "for cand_count in candidate_counts:\n",
    "    for city_count in city_counts:\n",
    "        lifts.append( (n_tweets * combo_counts[i]) / (cand_count * city_count) )\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifts = np.reshape(lifts, (2, 2)).T # reshape for similarities matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = pd.DataFrame(lifts, columns=['beto', 'cruz'], index=['big city', 'small city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Lift Matrix<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beto</th>\n",
       "      <th>cruz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>big city</th>\n",
       "      <td>0.779859</td>\n",
       "      <td>0.796016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small city</th>\n",
       "      <td>0.773519</td>\n",
       "      <td>0.733456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beto      cruz\n",
       "big city    0.779859  0.796016\n",
       "small city  0.773519  0.733456"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start sentimental stuff :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define <i>get_substring(key_word, s)<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask if key word in the string\n",
    "# split into list\n",
    "# identify the index of the key word\n",
    "# get list of +/- 3 indexes from key word\n",
    "# concated list back to string\n",
    "# return string\n",
    "def get_substring(key_word, s):\n",
    "    \"\"\"\n",
    "        1. ask if key word in the string\n",
    "        2. split into list\n",
    "        3. identify the index of the key word\n",
    "        4. get list of +/- radius indexes from key word\n",
    "        5. concated list back to string\n",
    "        6. return string\n",
    "    \"\"\"\n",
    "\n",
    "    # get rid of \"b'\" at beginning of tweet\n",
    "    s = s[2:]\n",
    "\n",
    "    # get rid of rt stuff if there\n",
    "    if 'rt @' in s:\n",
    "        end_of_rt = s.index(':')+2\n",
    "        s = s[end_of_rt:]\n",
    "\n",
    "    s_list = s.split()\n",
    "\n",
    "    radius = 5 # set the radius\n",
    "\n",
    "    # using this ugly mess to try to get beto or cruz if they are next to commas or exclamation\n",
    "    try:\n",
    "        kw_index = s_list.index(key_word)\n",
    "    except:\n",
    "        try:\n",
    "            kw_index = s_list.index(key_word+',')\n",
    "        except:\n",
    "            try:\n",
    "                kw_index = s_list.index(key_word+'!')\n",
    "            except:\n",
    "                try:\n",
    "                    kw_index = s_list.index(key_word+'.')\n",
    "                except:\n",
    "                    return\n",
    "\n",
    "    # get up until key word\n",
    "    sub_s_beg = []\n",
    "    if radius > kw_index:\n",
    "        sub_s_beg = s_list[:kw_index]\n",
    "    else:\n",
    "        sub_s_beg = s_list[kw_index-radius:kw_index]\n",
    "\n",
    "    # get key word and after\n",
    "    len_kw_index_to_end = len(s_list[kw_index+1:])\n",
    "    sub_s_end = []\n",
    "    if radius < len_kw_index_to_end:\n",
    "        sub_s_end = s_list[kw_index:kw_index+radius+1]\n",
    "    else:\n",
    "        sub_s_end = s_list[kw_index:]\n",
    "\n",
    "    sub_s = (' ').join(sub_s_beg + sub_s_end)\n",
    "    return sub_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_sent = []\n",
    "bs_sent = []\n",
    "cb_sent = []\n",
    "cs_sent = []\n",
    "for t in tweets.itertuples():\n",
    "\n",
    "    if t.location == 'Big':\n",
    "        if 'beto' in t.text:\n",
    "            sub_text = get_substring('beto', t.text)\n",
    "            if sub_text:\n",
    "                snt = analyser.polarity_scores(sub_text)\n",
    "                bb_sent.append(snt['compound'])\n",
    "            \n",
    "        if 'cruz' in t.text:\n",
    "            sub_text = get_substring('cruz', t.text)\n",
    "            if sub_text:\n",
    "                snt = analyser.polarity_scores(sub_text)\n",
    "                cb_sent.append(snt['compound'])\n",
    "            \n",
    "    elif t.location == 'Small':\n",
    "        if 'beto' in t.text:\n",
    "            sub_text = get_substring('beto', t.text)\n",
    "            if sub_text:\n",
    "                snt = analyser.polarity_scores(sub_text)\n",
    "                bs_sent.append(snt['compound'])\n",
    "\n",
    "        if 'cruz' in t.text:\n",
    "            sub_text = get_substring('cruz', t.text)\n",
    "            if sub_text:\n",
    "                snt = analyser.polarity_scores(sub_text)\n",
    "                cs_sent.append(snt['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average of list\n",
    "def avg(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order [0] beto/big [1] cruz/big [2] beto/small [3] cruz/small\n",
    "sentiments = [avg(bb_sent), avg(cb_sent), avg(bs_sent), avg(cs_sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = np.reshape(sentiments, (2, 2)) # reshape for similarities matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = pd.DataFrame(sentiments, columns=['beto', 'cruz'], index=['big city', 'small city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Sentiment matrix<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beto</th>\n",
       "      <th>cruz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>big city</th>\n",
       "      <td>0.063009</td>\n",
       "      <td>-0.033636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small city</th>\n",
       "      <td>0.080568</td>\n",
       "      <td>-0.026323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beto      cruz\n",
       "big city    0.063009 -0.033636\n",
       "small city  0.080568 -0.026323"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task E\n",
    "\n",
    "_Note: It needs to be addressed that our results would be better if ran on more data. From our original dataset of 4000+ tweets, we only found just over 400 with locations equal to a legitiment locations in Texas. This is very limiting, and will effect the legitimacy of our results. In our coming analysis, we assume that our data is legitement for the purpose of this assignment._\n",
    "\n",
    "Our lift matrix between the candidates and big/small cities in Texas tells us that Beto is talked about more by people from small cities and Cruz in big cities. This differences are very small, only changes to the 100th's decimal place. Because of the results given from this data it is hard to give any advice from lift values only.\n",
    "\n",
    "For our sentiment analysis, it was clear that sentiment was negative for Cruz and positive for Beto. \n",
    "\n",
    "For advice, we need to let Ted Cruz's campaign know that on Twitter, sentiment towards their candidate is generally negative. This should be addressed by their campain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
